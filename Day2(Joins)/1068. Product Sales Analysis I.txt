#SQL
select p.product_name, s.year, s.price
from Sales s Join Product p on s.product_id = p.product_id

#PANDAS
import pandas as pd

def sales_analysis(sales: pd.DataFrame, product: pd.DataFrame) -> pd.DataFrame:
    return pd.merge(sales, product, on='product_id')[['product_name', 'year', 'price']]

#PYSPARK
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("CreateSalesAndProductDataFrames").getOrCreate()

sales_data = [
    (1, 100, 2008, 10, 5000),
    (2, 100, 2009, 12, 5000),
    (7, 200, 2011, 15, 9000)
]
sales_columns = ["sale_id", "product_id", "year", "quantity", "price"]
sales = spark.createDataFrame(sales_data, sales_columns)

product_data = [
    (100, "Nokia"),
    (200, "Apple"),
    (300, "Samsung")
]
product_columns = ["product_id", "product_name"]
product = spark.createDataFrame(product_data, product_columns)

processed_data = sales.join(product, on='product_id').select('product_name', 'year', 'price')
processed_data.show()